{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 2: Model + LightningModule + Logging\n",
    "\n",
    "Objective: Implement model architectures (Custom CNN, ResNet), encapsulate them\n",
    "           in a PyTorch Lightning LightningModule, and set up comprehensive\n",
    "           logging for training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Imports ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import AdamW # Example optimizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau # Example scheduler\n",
    "# Add metrics imports later if needed (e.g., from torchmetrics)\n",
    "# --- Imports ---\n",
    "# ... (existing imports) ...\n",
    "import torchmetrics # Make sure torchmetrics is installed (pip install torchmetrics)\n",
    "\n",
    "# Specific metrics (adjust average strategy as needed)\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score, MulticlassAUROC, ConfusionMatrix\n",
    "\n",
    "# --- Configuration ---\n",
    "# These might be loaded from a config file or CLI args in a real script\n",
    "NUM_CLASSES = 7 # From our NSCLC dataset\n",
    "LEARNING_RATE = 1e-4\n",
    "# ... other relevant configurations ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Introduction to Histology Image Modeling\n",
    "\n",
    "Histology image classification involves training models to recognize patterns\n",
    "in tissue samples, often stained (e.g., H&E). Key challenges include:\n",
    "- **Large Image Size:** Whole Slide Images (WSIs) are massive, requiring patch-based approaches.\n",
    "- **Subtle Features:** Distinguishing between classes often relies on fine-grained details.\n",
    "- **Stain Variability:** Differences in staining protocols can affect image appearance.\n",
    "- **Class Imbalance:** Some tissue types might be much rarer than others.\n",
    "\n",
    "**Common Approaches:**\n",
    "- **Binary Classification:** Distinguishing between two states (e.g., tumor vs. normal).\n",
    "- **Multi-Class Classification:** Assigning patches to one of several predefined categories (like our 7 region types).\n",
    "- **Transfer Learning:** Leveraging models pre-trained on large datasets (like ImageNet) and fine-tuning them for the specific histology task (often beneficial).\n",
    "- **Custom Architectures:** Designing CNNs tailored to the specific characteristics of histology data.\n",
    "\n",
    "This section focuses on implementing a custom CNN as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleHistologyCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A basic Convolutional Neural Network for histology patch classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        # Define convolutional layers\n",
    "        # Example: (Input channels, Output channels, Kernel size, Stride, Padding)\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # Reduces spatial dims by half\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1)) # Global Average Pooling\n",
    "\n",
    "        # Placeholder for calculating the flattened size dynamically\n",
    "        # We'll need to pass a dummy input through the conv layers once\n",
    "        self._feature_size = None\n",
    "        self._calculate_feature_size() # Calculate size during init\n",
    "\n",
    "        # # Define fully connected layers\n",
    "        # self.fc1 = nn.Linear(self._feature_size, 128)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        # self.dropout = nn.Dropout(0.5) # Dropout for regularization\n",
    "        # self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _calculate_feature_size(self):\n",
    "        \"\"\"Helper to determine the size of the flattened features after conv layers.\"\"\"\n",
    "        # Create a dummy input matching expected dimensions (Batch, Channels, Height, Width)\n",
    "        # Assuming input patches are, for example, 256x256\n",
    "        # Adjust the dummy input size if your patches are different!\n",
    "        dummy_input = torch.randn(1, 3, 256, 256) # Example size\n",
    "        x = self.pool1(self.relu1(self.conv1(dummy_input)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        # Flatten the output\n",
    "        self._feature_size = x.view(x.size(0), -1).shape[1]\n",
    "        print(f\"Calculated feature size after conv layers: {self._feature_size}\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional part\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        # Global Average Pooling\n",
    "        x = self.gap(x)\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ LightningModule: Encapsulating Model & Training Logic\n",
    "\n",
    "A `pytorch_lightning.LightningModule` organizes the PyTorch code related to training,\n",
    "validation, and testing. It encapsulates:\n",
    "- The model architecture (our CNN or ResNet).\n",
    "- The forward pass logic.\n",
    "- The calculation of the loss.\n",
    "- The code performed during training, validation, and test steps.\n",
    "- The configuration of optimizers and learning rate schedulers.\n",
    "\n",
    "This makes the code cleaner, more reusable, and integrates seamlessly with the\n",
    "Lightning `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistologyClassifier(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning Module for histology image classification.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 encoder_name: str = 'resnet18', # Or 'custom_cnn'\n",
    "                 num_classes: int = NUM_CLASSES,\n",
    "                 learning_rate: float = LEARNING_RATE,\n",
    "                 optimizer: str = 'AdamW',\n",
    "                 lr_scheduler: str = 'ReduceLROnPlateau',\n",
    "                 pretrained: bool = True): # Added pretrained flag\n",
    "        super().__init__()\n",
    "        # Save hyperparameters for logging and potential loading later\n",
    "        # Important: Don't save the actual model instance here if it's large or complex\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "\n",
    "        if encoder_name == 'resnet18':\n",
    "            self.encoder = models.resnet18(pretrained=pretrained) # Load pretrained ResNet18\n",
    "            # remove the fully connected, and give the number of channels of the output layer\n",
    "            num_ftrs = self.encoder.fc.in_features\n",
    "            self.encoder.fc = nn.Identity() # Remove the final fully connected layer\n",
    "        elif encoder_name == 'custom_cnn':\n",
    "            self.encoder = SimpleHistologyCNN(num_classes=num_classes)\n",
    "            # For custom CNN, we need to define the final fully connected layer\n",
    "            num_ftrs = self.encoder._feature_size # Get the calculated feature size\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported encoder: {encoder_name}\")\n",
    "\n",
    "        ##########################\n",
    "        ## WRITE YOUR CODE HERE ##\n",
    "        ##########################\n",
    "        self.fc = ...  # Adjust for number of classes\n",
    "\n",
    "        # Loss function (CrossEntropyLoss is common for multi-class classification)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Example placeholder for metrics (we'll add proper ones in Task 4.3)\n",
    "        # from torchmetrics.classification import MulticlassAccuracy\n",
    "        # self.accuracy = MulticlassAccuracy(num_classes=num_classes)\n",
    "        metric_args = {'num_classes': num_classes, 'average': 'macro'}\n",
    "\n",
    "        self.train_metrics = torchmetrics.MetricCollection({\n",
    "            ##########################\n",
    "            ## WRITE YOUR CODE HERE ##\n",
    "            ##########################\n",
    "            # AUC requires probabilities or logits\n",
    "            # 'auroc': MulticlassAUROC(**metric_args, thresholds=None) # Use default thresholds\n",
    "        })\n",
    "        self.val_metrics = self.train_metrics.clone(prefix='val_') # Clone with prefix\n",
    "        self.test_metrics = self.train_metrics.clone(prefix='test_') # Clone with prefix\n",
    "\n",
    "        # Separate AUROC metric as it requires logits/probabilities directly\n",
    "        # auroc_args = {'num_classes': num_classes, 'average': 'macro', 'thresholds': None}\n",
    "        # self.train_auroc = MulticlassAUROC(**auroc_args)\n",
    "        # self.val_auroc = MulticlassAUROC(**auroc_args)\n",
    "        # self.test_auroc = MulticlassAUROC(**auroc_args)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward pass is simply delegated to the underlying model\n",
    "        x = self.encoder(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def _calculate_loss(self, batch, batch_idx, stage='train'):\n",
    "        images, labels = batch\n",
    "        logits = self.forward(images)\n",
    "        loss = self.criterion(logits, labels)\n",
    "\n",
    "        # --- Log Loss ---\n",
    "        self.log(f'{stage}_loss_step', loss, on_step=True, on_epoch=False, prog_bar=False, logger=True)\n",
    "        self.log(f'{stage}_loss_epoch', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # --- Calculate & Log Metrics ---\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        # Apply softmax to get probabilities for AUROC\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        # Select the correct metric collection based on the stage\n",
    "        if stage == 'train':\n",
    "            metrics_obj = self.train_metrics\n",
    "            # auroc_obj = self.train_auroc\n",
    "        elif stage == 'val':\n",
    "            metrics_obj = self.val_metrics\n",
    "            # auroc_obj = self.val_auroc\n",
    "        elif stage == 'test':\n",
    "            metrics_obj = self.test_metrics\n",
    "            # auroc_obj = self.test_auroc\n",
    "        else:\n",
    "             raise ValueError(f\"Invalid stage: {stage}\")\n",
    "\n",
    "        # Update metrics\n",
    "        metrics_obj.update(preds, labels)\n",
    "        # auroc_obj.update(probs, labels) # AUROC uses probabilities/logits\n",
    "\n",
    "        # Log metrics at the end of the epoch\n",
    "        self.log_dict(metrics_obj, on_step=False, on_epoch=True, logger=True)\n",
    "        # self.log(f'{stage}_auroc', auroc_obj, on_step=False, on_epoch=True, logger=True) # Log AUROC separately\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Defines the logic for a single training step\n",
    "        return self._calculate_loss(batch, batch_idx, stage='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Defines the logic for a single validation step\n",
    "        # This is used to monitor performance on unseen data during training\n",
    "        return self._calculate_loss(batch, batch_idx, stage='val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Defines the logic for a single testing step\n",
    "        # This is used after training to evaluate the final model performance\n",
    "        return self._calculate_loss(batch, batch_idx, stage='test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Choose optimizers and learning-rate schedulers to use during training.\n",
    "        \"\"\"\n",
    "        # If pretrained is True, freeze encoder parameters (do not train encoder)\n",
    "        if self.hparams.pretrained:\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Collect parameters to optimize (only trainable ones)\n",
    "        params_to_optimize = (\n",
    "            list(filter(lambda p: p.requires_grad, self.encoder.parameters())) +\n",
    "            list(self.global_avg_pool.parameters()) +\n",
    "            list(self.flatten.parameters()) +\n",
    "            list(self.fc.parameters())\n",
    "        )\n",
    "\n",
    "        if self.hparams.optimizer.lower() == 'adamw':\n",
    "            optimizer = AdamW(\n",
    "            params_to_optimize,\n",
    "            lr=self.hparams.learning_rate\n",
    "            )\n",
    "        elif self.hparams.optimizer.lower() == 'adam':\n",
    "            optimizer = torch.optim.Adam(\n",
    "            params_to_optimize,\n",
    "            lr=self.hparams.learning_rate\n",
    "            )\n",
    "        # Add other optimizers like SGD if needed\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer: {self.hparams.optimizer}\")\n",
    "\n",
    "        # Configure learning rate scheduler if specified\n",
    "        if self.hparams.lr_scheduler.lower() == 'reducelronplateau':\n",
    "            # Reduce learning rate when validation loss plateaus\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "            return {\n",
    "                'optimizer': optimizer,\n",
    "                'lr_scheduler': {\n",
    "                    'scheduler': scheduler,\n",
    "                    'monitor': 'val_loss_epoch', # Metric to monitor\n",
    "                    'interval': 'epoch',\n",
    "                    'frequency': 1\n",
    "                }\n",
    "            }\n",
    "        elif self.hparams.lr_scheduler.lower() == 'none':\n",
    "            return optimizer # Return only the optimizer if no scheduler\n",
    "        else:\n",
    "             raise ValueError(f\"Unsupported lr_scheduler: {self.hparams.lr_scheduler}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Evaluation\n",
    "\n",
    "Choosing appropriate metrics is crucial for evaluating classification performance,\n",
    "especially in medical imaging where class imbalance can be common. We use:\n",
    "\n",
    "- **Accuracy:** Overall percentage of correct predictions. Can be misleading if classes are imbalanced.\n",
    "- **Precision:** Of the samples predicted as positive, how many actually were? (TP / (TP + FP)). High precision means fewer false positives. Important when the cost of a false positive is high.\n",
    "- **Recall (Sensitivity):** Of the actual positive samples, how many were correctly identified? (TP / (TP + FN)). High recall means fewer false negatives. Important when the cost of missing a positive case is high.\n",
    "- **F1-Score:** The harmonic mean of precision and recall (2 * (Precision * Recall) / (Precision + Recall)). Provides a balance between precision and recall.\n",
    "- **AUC (Area Under the ROC Curve):** Measures the model's ability to distinguish between classes across all possible thresholds. An AUC of 1.0 is perfect, 0.5 is random guessing. Often a good overall measure, especially for imbalanced datasets.\n",
    "\n",
    "We use `'macro'` averaging, which calculates the metric independently for each class and then takes the unweighted average. This treats all classes equally, regardless of their size. `'weighted'` averaging considers class support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbenimam/Documents/work/neubias/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mbenimam/Documents/work/neubias/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "plModel = HistologyClassifier(\n",
    "    encoder_name='resnet18',\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    optimizer='AdamW',\n",
    "    lr_scheduler='ReduceLROnPlateau',\n",
    "    pretrained=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbenimam/Documents/work/neubias/venv/lib/python3.10/site-packages/pytorch_lightning/core/module.py:441: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step loss: 2.183617353439331\n",
      "Validation step loss: 2.183617353439331\n",
      "Test step loss: 2.183617353439331\n"
     ]
    }
   ],
   "source": [
    "# simulate batch with labels\n",
    "batch = (torch.randn(8, 3, 256, 256), torch.randint(0, NUM_CLASSES, (8,)))\n",
    "# Example training step\n",
    "loss = plModel.training_step(batch, 0)\n",
    "print(f\"Training step loss: {loss.item()}\")\n",
    "# Example validation step\n",
    "val_loss = plModel.validation_step(batch, 0)\n",
    "print(f\"Validation step loss: {val_loss.item()}\")\n",
    "# Example test step\n",
    "test_loss = plModel.test_step(batch, 0)\n",
    "print(f\"Test step loss: {test_loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
